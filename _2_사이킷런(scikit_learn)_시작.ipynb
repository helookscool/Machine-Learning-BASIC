{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwm3Ce3oIgYi"
   },
   "source": [
    "# 사이킷런(scikit-learn) 시작\n",
    "\n",
    "![scikit-learn logo.png](https://drive.google.com/uc?id=1Aeb0mBJzYgz7UGmHAdGsQJF44EM9mNTD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhF1mufkp8TQ"
   },
   "source": [
    "## scikit-learn 특징\n",
    "\n",
    "* 다양한 머신러닝 알고리즘을 구현한 파이썬 라이브러리\n",
    "* 심플하고 일관성 있는 API, 유용한 온라인 문서, 풍부한 예제\n",
    "* 머신러닝을 위한 쉽고 효율적인 개발 라이브러리 제공\n",
    "* 다양한 머신러닝 관련 알고리즘과 개발을 위한 프레임워크와 API 제공\n",
    "* 많은 사람들이 사용하며 다양한 환경에서 검증된 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19ORAlQckvSb"
   },
   "source": [
    "## scikit-learn 주요 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4luZ6ock5rm"
   },
   "source": [
    "| 모듈 | 설명 |\n",
    "|------|------|\n",
    "| `sklearn.datasets` | 내장된 예제 데이터 세트 |\n",
    "| `sklearn.preprocessing` | 다양한 데이터 전처리 기능 제공 (변환, 정규화, 스케일링 등) |\n",
    "| `sklearn.feature_selection` | 특징(feature)를 선택할 수 있는 기능 제공 | \n",
    "| `sklearn.feature_extraction` | 특징(feature) 추출에 사용 |\n",
    "| `sklearn.decomposition` | 차원 축소 관련 알고리즘 지원 (PCA, NMF, Truncated SVD 등)\n",
    "| `sklearn.model_selection` | 교차 검증을 위해 데이터를 학습/테스트용으로 분리, 최적 파라미터를 추출하는 API 제공 (GridSearch 등)\n",
    "| `sklearn.metrics` | 분류, 회귀, 클러스터링, Pairwise에 대한 다양한 성능 측정 방법 제공 (Accuracy, Precision, Recall, ROC-AUC, RMSE 등) |\n",
    "| `sklearn.pipeline` | 특징 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 묶어서 실행할 수 있는 유틸리티 제공 |\n",
    "| `sklearn.linear_model` | 선형 회귀, 릿지(Ridge), 라쏘(Lasso), 로지스틱 회귀 등 회귀 관련 알고리즘과 SGD(Stochastic Gradient Descent) 알고리즘 제공 |\n",
    "| `sklearn.svm` | 서포트 벡터 머신 알고리즘 제공 |\n",
    "| `sklearn.neighbors` | 최근접 이웃 알고리즘 제공 (k-NN 등)\n",
    "| `sklearn.naive_bayes` | 나이브 베이즈 알고리즘 제공 (가우시안 NB, 다항 분포 NB 등) |\n",
    "| `sklearn.tree` | 의사 결정 트리 알고리즘 제공 |\n",
    "| `sklearn.ensemble` | 앙상블 알고리즘 제공 (Random Forest, AdaBoost, GradientBoost 등) |\n",
    "| `sklearn.cluster` | 비지도 클러스터링 알고리즘 제공 (k-Means, 계층형 클러스터링, DBSCAN 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikDZ-kpFo06o"
   },
   "source": [
    "## `estimator` API\n",
    "(사이킷런이 어떤 식으로 이 api를 사용할 수 있는지에 대한 규칙을 좀 알아 둘 필요가 았다.)\n",
    "* 일관성: 모든 객체는 일관된 문서를 갖춘 제한된 메서드 집합에서 비롯된 공통 인터페이스 공유\n",
    "* 검사(inspection): 모든 지정된 파라미터 값은 공개 속성으로 노출\n",
    "* 제한된 객체 계층 구조\n",
    "  + 알고리즘만 파이썬 클래스에 의해 표현\n",
    "  + 데이터 세트는 표준 포맷(NumPy 배열, Pandas DataFrame, Scipy 희소 행렬)으로 표현\n",
    "  + 매개변수명은 표준 파이썬 문자열 사용\n",
    "* 구성: 많은 머신러닝 작업은 기본 알고리즘의 시퀀스로 나타낼 수 있으며, Scikit-Learn은 가능한 곳이라면 어디서든 이 방식을 사용\n",
    "* 합리적인 기본값: 모델이 사용자 지정 파라미터를 필요로 할 때 라이브러리가 적절한 기본값을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKXC0zoTrmHM"
   },
   "source": [
    "### API 사용 방법\n",
    "\n",
    "1. Scikit-Learn으로부터 적절한 `estimator` 클래스를 임포트해서 모델의 클래스 선택\n",
    "2. 클래스를 원하는 값으로 인스턴스화(즉각적으로 쓰일수 있게 한다는 뜻인듯, 클래스를 콜하는것을 말함)해서 모델의 하이퍼파라미터 선택\n",
    "3. 데이터를 특징 배열(feature를 말함, X)과 대상 벡터(타겟을 말함,y)로 배치\n",
    "4. 모델 인스턴스의 `fit()` 메서드를 호출해 모델을 데이터에 적합\n",
    "5. 모델을 새 데이터에 대해서 적용\n",
    "  + 지도 학습: 대체로 `predict()` 메서드를 사용해 알려지지 않은 데이터에 대한 레이블 예측\n",
    "  + 비지도 학습: 대체로 `transform()`이나 `predict()` 메서드를 사용해 데이터의 속성을 변환하거나 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WgAOokAPVvG"
   },
   "source": [
    "![scikit-learn](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "사이킷런의 치트시트임. 과연 내가 어떠한 estimator를 선택해야 할 것인가, 내가 데이터를 통해서 어떠한 모델을 수행해야지 적합한지에 대해서 판단할 수 있는 기준이 되는 로드맵같은 그림임. \n",
    "\n",
    "quantity(양적정보)는 연속적인 수치형 값을 가지는 것들을 예측할 때 사용하는것.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-8ca4c07732fc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-8ca4c07732fc>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    conda update -n base conda\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda update -n base conda\n",
    "conda update --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lEfpb55skvd"
   },
   "source": [
    "### API 사용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bxt8A5iQoHbc"
   },
   "outputs": [],
   "source": [
    "#에스티메이터 API를 사용하는것을 아주 간단하게 따라해보자. \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt. style.use(['seaborn-whitegrid'])#자기가 좋아하는 스타일이래"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "Ct9fa3T_s6nV",
    "outputId": "685fad45-fada-448d-b466-8c5bc025aff5"
   },
   "outputs": [],
   "source": [
    "x = 10 * np.random.rand(50)\n",
    "y = 2 * x + np.random.rand(50)\n",
    "plt.scatter(x,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mYOpr_XubH2"
   },
   "outputs": [],
   "source": [
    "#API사용방법 1. Scikit-Learn으로부터 적절한 estimator 클래스를 임포트해서 모델의 클래스 선택\n",
    "\n",
    "from sklearn.linear_model import LinearRegression #걍...그래프가 선형이니까 선택해봤데.\n",
    "# LinearRegression은 linear_model 안에 들어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciPMcnzzzkDY",
    "outputId": "83b5b869-3cc9-491d-891b-e4b8b64c066d"
   },
   "outputs": [],
   "source": [
    "#API사용방법 2. 클래스를 원하는 값으로 인스턴스화(즉각적으로 쓰일수 있게 한다는 뜻인듯, 클래스를 콜하는것을 말함)해서 모델의 하이퍼파라미터 선택\n",
    "\n",
    "model = LinearRegression(fit_intercept=True) #하이퍼파라미터가 fit_intercept=True 임 \n",
    "model # 결과창의 copy_X는 실질적으로 사용되고 있는 이 입력데이터를 복사 해서 사용할거냐 안해서 사용할거냐 라는 뜻, 디폴트는 트루임.\n",
    "#fit_intercept=True 상수형태의 값을 다루는 것을 의미. 지금 상수형태의 값을 다루고 있으므로 트루를 했음., 디폴트 트루임. 괜히 써봤음\n",
    "#n_jobs=None 모델을 돌릴때, 여러개의 job을 띄워서 돌릴수 있음. 데이터가 크면 CPU에 병렬로 해서 여러개 알고리즘을 동시에 돌리기도 함\n",
    "# normalize=False  normalize, 정규화를 말함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7OWKXAbz7nd",
    "outputId": "0971664a-0d8e-46b9-ef8a-b6422eb3271b"
   },
   "outputs": [],
   "source": [
    "#API사용방법 3. 데이터를 특징 배열(feature를 말함, X)과 대상 벡터(타겟을 말함,y)로 배치\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYDjfXEf0Fqt",
    "outputId": "52b46ffd-a16a-4019-e0eb-8a730fd2877e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4ac5cd836abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#기존의 x는 위의 넘파이 어래이 형태로 출력이 됐지만, 피쳐의 배열 형식으로 바꿔주기 위해서\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;31m#축이 하나가 추가가 되서 2차원 형태로...만들었다는데 이해는 안되네.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#y는 그대로 사용하면 되니까 x만 특징변환으로 배열했다...라네?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#기존의 x는 위의 넘파이 어래이 형태로 출력이 됐지만, 피쳐의 배열 형식으로 바꿔주기 위해서 \n",
    "X=x[:, np.newaxis]\n",
    "X #축이 하나가 추가가 되서 2차원 형태로...만들었다는데 이해는 안되네. \n",
    "#y는 그대로 사용하면 되니까 x만 특징변환으로 배열했다...라네?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vw8MU5Ug0JDl",
    "outputId": "3cdb9801-6444-4b4b-9b23-86b2056f8d50"
   },
   "outputs": [],
   "source": [
    "#API사용방법 4. 모델 인스턴스의 fit() 메서드를 호출해 모델을 데이터에 적합\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxUYZU4f0Ktg",
    "outputId": "ee131b91-2750-40b9-962b-e4103cdb3064"
   },
   "outputs": [],
   "source": [
    "model.coef_ #이 내용들은 선형회귀에서 다루도록 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIq6q0lb1oyD",
    "outputId": "9e4a4452-a029-4f40-9227-1f618bc708d2"
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsBjQcoIl_6B"
   },
   "outputs": [],
   "source": [
    "#API사용방법 5. 모델을 새 데이터에 대해서 적용\n",
    "xfit = np.linspace(-1,11) #새로운 데이터를 linspace를 통해 하나 만들었고, \n",
    "Xfit=xfit[:, np.newaxis] #xfit을 newaxis로 축을 추가해주고, 2차원 형태로 만들어주고(특징배열로 만들어 준다고)\n",
    "yfit = model.predict(Xfit) #yfit 은 모델의 predict라는 함수를 통해서 예측을 해보는데, 여기에 Xfit이라는 새로운 데이터를 추가해줬음\n",
    "#예측한 결과를 yfit으로 집어 넣었다. 이걸 차트로 한번 나타내어 보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "rBQjjviAtr5H",
    "outputId": "c1a6ec9c-bbce-4568-d54d-05aef0e670be"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y);\n",
    "plt.plot(xfit,yfit, '--r' ) #선형회귀니까 xfit,yfit 해주고 점선에 빨간색으로 그려보자.\n",
    "# 지금 x, y형태의 출력되있는 기본 데이터에 대해서 지금 빨간색으로 예측을 했음. \n",
    "#이런식으로 사이킷런의 기본 PAI인  estimator API를 어떤식으로 사용해 볼것인지 알아봤다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29de3S_Kon64"
   },
   "source": [
    "## 예제 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb8VoXDioqmL"
   },
   "source": [
    "### 분류 또는 회귀용 데이터 세트\n",
    "\n",
    "| API | 설명 |\n",
    "|-----|------|\n",
    "| `datasets.load_boston()` | 미국 보스턴의 집에 대한 특징과 가격 데이터 (회귀용) |\n",
    "| `datasets.load_breast_cancer()` | 위스콘신 유방암 특징들과 악성/음성 레이블 데이터 (분류용) |\n",
    "| `datasets.load_diabetes()` | 당뇨 데이터 (회귀용) |\n",
    "| `datasets.load_digits()` | 0에서 9까지 숫자 이미지 픽셀 데이터 (분류용) |\n",
    "| `datasets.load_iris()` | 붓꽃에 대한 특징을 가진 데이터 (분류용) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbpkiHGK1Tce"
   },
   "source": [
    "### 온라인 데이터 세트\n",
    "\n",
    "* 데이터 크기가 커서 온라인에서 데이터를 다운로드 한 후에 불러오는 예제 데이터 세트\n",
    "\n",
    "| API | 설명 |\n",
    "|-----|------|\n",
    "| `fetch_california_housing()` | 캘리포니아 주택 가격 데이터 |\n",
    "| `fetch_covtype()` | 회귀 분석용 토지 조사 데이터 |\n",
    "| `fetch_20newsgroups()` | 뉴스 그룹 텍스트 데이터 |\n",
    "| `fetch_olivetti_faces()` | 얼굴 이미지 데이터 |\n",
    "| `fetch_lfw_people()` | 얼굴 이미지 데이터 |\n",
    "| `fetch_lfw_paris()` | 얼굴 이미지 데이터 |\n",
    "| `fetch_rcv1()` | 로이터 뉴스 말뭉치 데이터 |\n",
    "| `fetch_mldata()` | ML 웹사이트에서 다운로드 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRecl-l_1UFE"
   },
   "source": [
    "### 분류와 클러스터링을 위한 표본 데이터 생성\n",
    "\n",
    "| API | 설명 |\n",
    "|-----|------|\n",
    "| `datasets.make_classifications()` | 분류를 위한 데이터 세트 생성. 높은 상관도, 불필요한 속성 등의 노이즈를 고려한 데이터를 무작위로 생성 |\n",
    "| `datasets.make_blobs()` | 클러스터링을 위한 데이터 세트 생성. 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 셋트를 무작위로 생성 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn8I5U0D4tP7"
   },
   "source": [
    "### 예제 데이터 세트 구조\n",
    "(슈퍼바이즈드 러닝이면 데이터, 즉 피텨를 통해서 타겟을 맞춰야 하는 구조)\n",
    "* 일반적으로 딕셔너리 형태로 구성\n",
    "* data: 특징 데이터 세트\n",
    "* target: 분류용은 레이블 값, 회귀용은 숫자 결과값 데이터. y값을 말함.\n",
    "* target_names: 개별 레이블의 이름 (분류용)\n",
    "* feature_names: 특징 이름\n",
    "* DESCR: 데이터 세트에 대한 설명과 각 특징 설명(DESCRIPTION임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4Xvo4kg6dHS",
    "outputId": "ccb93270-1cd0-4834-b661-c17987a8c4d0"
   },
   "outputs": [],
   "source": [
    "#아무거나 불러서 함 해보자.\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "print(diabetes. keys())#일단 키만 한번 봐보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuvZHGQ18cX-",
    "outputId": "83727132-749c-4505-e2a6-381727c666e2"
   },
   "outputs": [],
   "source": [
    "#함 쭉 봐보자.\n",
    "print(diabetes.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRmFh1oP8iKs",
    "outputId": "425235f0-d0b4-4029-f1da-68010eb1f202"
   },
   "outputs": [],
   "source": [
    "print(diabetes.target) #타겟이 숫자들로 구성되있는데, 회귀분석이니까, 수치형으로 구성되있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIg2ZbjG9XBm",
    "outputId": "45ed8b60-0130-4b25-9b9b-49fa51f5a017"
   },
   "outputs": [],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vLjpUAl8y3Z",
    "outputId": "ed3b2e34-dcdf-4de5-d7f7-90208b405112"
   },
   "outputs": [],
   "source": [
    "print(diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoSlB1kM8lpR",
    "outputId": "fa8c6b07-1bf0-4af4-a9ca-949a579217eb"
   },
   "outputs": [],
   "source": [
    "#데이터 파일들이 들어있는곳\n",
    "print(diabetes.data_filename)\n",
    "print(diabetes.target_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK7Xxb-4-s9r"
   },
   "source": [
    "## `model_selection` 모듈\n",
    "\n",
    "* 학습용 데이터와 테스트 데이터로 분리\n",
    "* 교차 검증 분할 및 평가\n",
    "* Estimator의 하이퍼 파라미터 튜닝을 위한 다양한 함수와 클래스 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoulI5Vo_C_Y"
   },
   "source": [
    "### `train_test_split()`: 학습/테스트 데이터 세트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6g2drBI_CFw",
    "outputId": "d27d772e-35bd-423f-8c32-598e639075ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes= load_diabetes()\n",
    "#train_test_split(features, target, test_size 트레인데이터와 테스트데이터의 크기 )\n",
    "#train_test_split는 총 4개의 데이터를 리턴시켜주는데 \n",
    "#여러개의 features를 표현할때 대문자X로 표현함, 매트릭스 형태는 이렇게 대문자로 표현하는데, \n",
    "#타겟이 되는 y값은 하나뿐이므로, 즉 매트릭스 형태가 아니라 벡터형태이기 때문에 소문자로 표현한다. \n",
    "X_train, X_test,y_train, y_test =train_test_split(diabetes.data, diabetes.target,test_size=0.3 )\n",
    "\n",
    "model = LinearRegression()\n",
    "#데이터를 학습시켜라 라는 명령어가 fit임.\n",
    "#학습용데이터를 가지고 합승을 해야 하니까, x자리에 넣을것은 X_train임. y자리는 y_train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#훈련점수도 함 프린트해보자\n",
    "print(\"학습데이터 점수: {}\".format(model.score(X_train, y_train)))\n",
    "print(\"평가데이터 점수: {}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "8vZFyqaoCpEC",
    "outputId": "4a8630dd-fe52-43b3-b0b8-8a17f9ee78b4"
   },
   "outputs": [],
   "source": [
    "#시각화\n",
    "predicted= model.predict(X_test)\n",
    "expected = y_test\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(expected, predicted)\n",
    "plt.plot([30,350], [30,350], '--r')\n",
    "plt.tight_layout()\n",
    "#빨간선이 정답인데 빨간선에 근접한 값들이 많지 않다. 그래서 점수가 50점 수준임. 모델을 바꾸거나, 데이터 전처리를 다시해야됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngFG3QwGD4e2"
   },
   "source": [
    "### `cross_val_score()`: 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnQp6pPTD9JM",
    "outputId": "cc0ca60b-135c-47c3-c9be-1b138479b732"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate #사이킷런에서 교차검증을 위해 제공되는 두가지\n",
    "#위에서 이미 당뇨병데이터셋 불러왔고, LinearRegression도 불러왔으니까 여기서는 교차검증만 간단히 해보자.\n",
    "scores = cross_val_score(model, diabetes.data, diabetes.target, cv=5)\n",
    "#cv->cross validation을 위해서 k폴드...k값을 정해줘야됨. cross validation을 위해서 몇개로 나눌지...5로 해보제.\n",
    "print(\"교차 검증 정확도: {}\".format(scores))#데이터 5개를 다 펼쳐서 보여주거나\n",
    "print(\"교차 검증 정확도: {} +/- {}\".format(np.mean(scores), np.std(scores)))#평균에서 표준편차만큼 +-해서 보여주거나\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpgCUVF7XN5x"
   },
   "source": [
    "### `GridSearchCV`: 교차 검증과 최적 하이퍼 파라미터 찾기\n",
    "\n",
    "* 훈련 단계에서 학습한 파라미터에 영향을 받아서 최상의 파라미터를 찾는 일은 항상 어려운 문제\n",
    "* 다양한 모델의 훈련 과정을 자동화하고, 교차 검사를 사용해 최적 값을 제공하는 도구 필요\n",
    "* `GridSearchCV`는 교차검증을 여러번 반복해서 최적의 하이퍼 파라미터를 찾아주는 메소드...데이터가 많으면 연산시간이 꽤길어져버리는 단점. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "xd96K4CuXMrU",
    "outputId": "b2b11e52-3411-4298-bba7-f88e86175ef0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ridge #선형 모델중에서 알파값을 조정해서 사용하는 릿지라는 모델 써보제\n",
    "#ridge는 나중에 배움\n",
    "import pandas as pd\n",
    "\n",
    "alpha = [0.001, 0.01, 0.1,1, 10, 100, 1000] #알파값 7개 써보제\n",
    "param_grid = dict(alpha=alpha)  #파라미터 그리드 조정\n",
    "#파라메터값이 다르게 한 형태로 교차검증하면서 모델을 계속 돌리는거임.\n",
    "gs= GridSearchCV(estimator=ridge(), param_grid=param_grid, cv=10)\n",
    "result = gs.fit(diabetes.data, diabetes.target)\n",
    "print(\"최적 점수: {}\".format(result.best_score_)) # 끝에 _ 붙혀줘야됨\n",
    "print(\"최적 점수: {}\".format(result.best_params_)) # 끝에 _ 붙혀줘야됨\n",
    "print((gs.best_estimator_) #끝에 _ 붙혀줘야됨\n",
    "\n",
    "pd.DataFrame(result.cv_results_) #result에 cv_results_가 있으니 이걸 출력해보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6tTVC3sagc9"
   },
   "source": [
    "* `multiprocessing`을 이용한 `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKxQLen3aBxT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5_bY2inmPfQ"
   },
   "source": [
    "## `preprocessing` 데이터 전처리 모듈\n",
    "\n",
    "* 데이터의 특징 스케일링(feature scaling)을 위한 방법으로 표준화(Standardization)와 정규화(Normalization) 사용\n",
    "\n",
    "+ 표준화 방법\n",
    "\n",
    "\\begin{equation}\n",
    "x_i^{'} = \\frac{x_i-mean(x)}{stdev(x)}\n",
    "\\end{equation}\n",
    "\n",
    "+ 정규화 방법\n",
    "\n",
    "\\begin{equation}\n",
    "x_i^{'} = \\frac{x_i-min(x)}{max(x)-min(x)}\n",
    "\\end{equation}\n",
    "\n",
    "+ scikit-learn에서는 개별 벡터 크기를 맞추는 형태로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzdqo4OSrhDI"
   },
   "source": [
    "### `StandardScaler`: 표준화 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3VZVnnyso1m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGtTNBFquBIS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwYeH_9k_Rog"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TctmHqowvBG"
   },
   "source": [
    "### `MinMaxScaler`: 정규화 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5_id8diw6l-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDmNGhWxy3NN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GleRpgpOAVPE"
   },
   "source": [
    "## 성능 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZW0mVKVBApg5"
   },
   "source": [
    "### 정확도(Accuracy)\n",
    "\n",
    "* 정확도는 전체 예측 데이터 건수 중 예측 결과가 동일한 데이터 건수로 계산\n",
    "* scikit-learn에서는 `accuracy_score` 함수를 제공\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5bYSmjiBOXK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEsjYTnbDR3A"
   },
   "source": [
    "### 오차 행렬(Confusion Matrix)\n",
    "\n",
    "* True Negative: 예측값을 Negative 값 0으로 예측했고, 실제 값도 Negative 값 0\n",
    "* False Positive: 예측값을 Positive 값 1로 예측했는데, 실제 값은 Negative 값 0\n",
    "* False Negative: 예측값을 Negative 값 0으로 예측했는데, 실제 값은 Positive 값 1\n",
    "* True Positive: 예측값을 Positive 값 1로 예측했고, 실제 값도 Positive 값 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYeVwfICEKcL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow3jcKmgEspA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLf4sth1FsQ_"
   },
   "source": [
    "### 정밀도(Precision)와 재현율(Recall)\n",
    "\n",
    "* 정밀도 = TP / (FP + TP)\n",
    "* 재현율 = TP / (FN + TP)\n",
    "\n",
    "* 정확도 = (TN + TP) / (TN + FP + FN + TP)\n",
    "* 오류율 = (FN + FP) / (TN + FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liPg5IBuGhpj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFeWdm3ZK-vW"
   },
   "source": [
    "### F1 Score(F-measure)\n",
    "\n",
    "* 정밀도와 재현율을 결합한 지표\n",
    "* 정밀도와 재현율이 어느 한쪽으로 치우치지 않을 때 높은 값을 가짐\n",
    "\n",
    "\\begin{equation}\n",
    "F1 = 2 \\times \\frac{precision \\times recall}{precision + recall}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5atW1FDLu-s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtgHCc08OAKp"
   },
   "source": [
    "### ROC 곡선과 AUC\n",
    "\n",
    "* ROC 곡선은 FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지 나타내는 곡선\n",
    "  + TPR(True Positive Rate): TP / (FN + TP), 재현율\n",
    "  + TNR(True Negative Rate): TN / (FP + TN)\n",
    "  + FPR(False Positive Rate): FP / (FP + TN), 1 - TNR\n",
    "\n",
    "* AUC(Area Under Curve) 값은 ROC 곡선 밑에 면적을 구한 값 (1이 가까울수록 좋은 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqVAbkiNU1UL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYMKyuPKWFNF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0H5n_UgMIx8"
   },
   "source": [
    "## 참고문헌\n",
    "\n",
    "* scikit-learn 사이트: https://scikit-learn.org/\n",
    "* Jake VanderPlas, \"Python Data Science Handbook\", O'Reilly\n",
    "* Sebastian Raschka, Vahid Mirjalili, \"Python Machine Learning\", Packt\n",
    "* Giuseppe Bonaccorso, \"Machine Learning Algorithm\", Packt\n",
    "* Aurelien Geron, \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\", O'Reilly"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UhF1mufkp8TQ",
    "Bb8VoXDioqmL",
    "LbpkiHGK1Tce",
    "sRecl-l_1UFE",
    "M5_bY2inmPfQ",
    "fzdqo4OSrhDI",
    "2TctmHqowvBG",
    "GleRpgpOAVPE",
    "ZW0mVKVBApg5",
    "lEsjYTnbDR3A",
    "LLf4sth1FsQ_",
    "iFeWdm3ZK-vW",
    "OtgHCc08OAKp",
    "R0H5n_UgMIx8"
   ],
   "name": "_2 사이킷런(scikit-learn) 시작",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
